# Authors: Code generated by Google Gemini and ChatGPT online and comments done by Daniel Holgate
# Date: 16/09/2025
# Description: Code for prompting LLaMA to generate a seven paragraph story without an event outline but with phoneme incorporation.

import os
import re
import subprocess
import random
from typing import List, Tuple

# For specifying where your model is located as well as the location of llama-cli which handles running the model for you.
# Must change them for your setup.
LLAMA_CLI_PATH = ""
MODEL_PATH = ""

MAX_CONTEXT_TOKENS = 8192 # Specifies the total number of tokens that the model can process at once.
# Specifies the limit of tokens that can be generated by the model in response to a prompt, per batch.
MAX_GENERATION_TOKENS_PER_BATCH = 500

# Files for input and output. Need to be adjusted for the files you are using. 
# The theme file is the output file from theme extraction, the source file is the output file from Match.py, the mistakes file is the 
# output file of Mistakes.py containing the five error phonemes to incorporate and the output file can be what you want.
THEME_FILE = ""
SOURCE_FILE = ""
MISTAKES_FILE = ""
OUTPUT_FILE = ""

# Method for going through the selected story file (matched source story) to find a specified story (by story number)
def extract_story_paragraphs_and_transitions(filepath: str, story_number: int) -> Tuple[List[str], List[str]]:
    print(f"Extracting story paragraphs and transitions for story {story_number} from {filepath}")
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()

    story_header = f"--- Story {story_number} ---"
    # Searches for the story header containing the specified story number.
    match = re.search(re.escape(story_header), text)
    if not match:
        raise ValueError(f"Story {story_number} not found in file.")

    # Extracts the separated paragraphs and transitions for the located story.
    story_start = match.end()
    rest = text[story_start:]

    block = re.split(r"--- Story \d+ ---", rest)[0]

    # Extracts all the individual paragraphs.
    paragraphs = re.findall(r"\[Paragraph \d+\](.*?)\n(?=\[|\Z)", block, re.DOTALL)
    paragraphs = [p.strip() for p in paragraphs if p.strip()]

    # Extracts all the individual transitions.
    transitions = []
    if "--- Paragraph Transitions ---" in block:
        trans_block = block.split("--- Paragraph Transitions ---", 1)[-1]
        raw_trans = re.findall(r"\[Transition \d+\]\s*(.*?)(?=\n\[Transition|\Z)", trans_block, re.DOTALL)
        transitions = [t.strip() for t in raw_trans if t.strip()]
        
    return paragraphs, transitions

# Method for reading in all the earlier extracted themes from which will select a random one to go with the initial paragraph.
def load_themes(theme_file: str) -> list[tuple[str, str]]:
    themes_data = []
    try:
        if not os.path.exists(theme_file):
            print(f"Error: Theme file '{theme_file}' not found.")
            return []

        with open(theme_file, "r", encoding="utf-8") as f:
            content = f.read()

        raw_blocks = re.split(r'---\s*\n', content)
        theme_word_pattern = re.compile(r"Theme Word:\s*(\w+)", re.IGNORECASE)
        theme_sentence_pattern = re.compile(r"Theme Sentence:\s*(.+)", re.IGNORECASE)

        # Goes through each theme block (pair of theme word and theme sentence) and keeps only the correctly formatted pairs.
        for block_content in raw_blocks:
            if not block_content.strip():
                continue
            word_match = theme_word_pattern.search(block_content)
            sentence_match = theme_sentence_pattern.search(block_content)

            theme_word = word_match.group(1).strip() if word_match else None
            theme_sentence = sentence_match.group(1).strip() if sentence_match else None

            if theme_word and theme_sentence:
                themes_data.append((theme_word, theme_sentence))
            else:
                if block_content.strip():
                    print(f"Warning: Incomplete theme block found:\n{block_content.strip()}\nMissing 'Theme Word:' or 'Theme Sentence:'.")

        if not themes_data:
            print(f"Warning: No complete 'Theme Word:' and 'Theme Sentence:' pairs found in '{theme_file}' using the expected format.")
        return themes_data

    except Exception as e:
        print(f"Error reading theme file or parsing themes: {e}")
        return []
    
# Method for extracting the five phonemes to incorporate into each paragraph of the story.
def load_mistakes(phoneme_file: str) -> list[str]:
    phonemes = []
    with open(phoneme_file, "r", encoding="utf-8") as f:
        for line in f:
            phonemes = line.split(" ")
    return phonemes

# The main function for generating each paragraph of the final output stories. 
# Takes in an input file, performs what is requested in the prompt and outputs the next paragraph.
def generate_continuation_paragraph(
    theme: str,
    story_so_far: List[str],
    previous_source_paragraph: str,
    current_source_paragraph: str,
    transition_text: str,
    llama_cli_path: str,
    model_path: str,
    max_context_tokens: int,
    max_generation_tokens_per_batch: int,
    phonemes: List[str]
) -> str:
    
    # Provides the prompt to the model for instructing it in how to generate an initial paragraph. Includes the theme
    # transition and phonemes to incorporate as well as the previous and current source paragraphs and the last paragraph generated
    # by the model.
    prompt_body = f"""
    
    I want to generate the continuation paragraph of a children's story for age 6.
    
    Continue the story as follows:
        The story must include the following:
            Theme: {theme}
            Transition: {transition_text}
            
        It must use as reference the following:
            Previous paragraph from the original story (reference):
            {previous_source_paragraph}
            
            Current paragraph from the original story (reference):
            {current_source_paragraph}
            
        It must carry on from this paragraph:
            Previous paragraph generated:
            {story_so_far[-1] if story_so_far else ""}

        Using all the above:
            - Write a new paragraph continuing the story.
            - Match the tone and theme.
            - Keep it imaginative and age-appropriate for age 6.
            - Do not repeat prior paragraphs.
            
    Please incorporate words with the sounds of {phonemes[0]}, {phonemes[1]}, {phonemes[2]}, {phonemes[3]}, {phonemes[4]} 
    where it makes sense to.
    Spell the words as they are spelt not how they would sound. This is important because these are phonemes you are incorporating.
            
    The grammar and vocabulary should match that of what a 6 year old could understand.
    
    If you are working on generating your 6th paragraph, the story needs to conclude in that paragraph.

Next paragraph:
###BEGIN###"""

    prompt = (
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n"
        + prompt_body
        + "\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"
    )

    # Specifies what variables need to be passed to what part of the model.
    command = [
        llama_cli_path,
        "-m", model_path,
        "-c", str(max_context_tokens),
        "-n", str(max_generation_tokens_per_batch),
        # Controls randomness. Higher leads to higher creativity but higher chance of incoherence. Lower is higher of just taking most
        # probable next token.
        "--temp", "0.7",
        # Controls nucleus sampling. Here chooses from the most likely of 90% of possible next tokens. Higher gives more variety in
        # words.
        "--top-p", "0.9",
        # Random number generator seed. If same one with same prompt and parameters should always get the same out.
        "--seed", str(random.randint(1, 10000)),
        "--prompt", prompt
    ]

    # Attempts to run the specified command for the model and returns what the model outputs to the standard output.
    try:
        result = subprocess.run(command, capture_output=True, text=True)
        output = result.stdout.strip()
    except subprocess.TimeoutExpired:
        print("Error: llama-cli subprocess timed out.")
        return "[ERROR: Generation timed out]"

    if result.returncode != 0:
        print("Error: llama-cli returned non-zero exit code.")
        print("stderr:", result.stderr)
        return "[ERROR: llama-cli failed]"

    if "###BEGIN###" in output:
        generated_text = output.split("###BEGIN###", 1)[-1].strip()
    else:
        generated_text = output.strip()

    return generated_text

# Method for generating the full output story paragraph by paragraph by calling the generate paragraph method 6 times.
def build_story(
    theme: str,
    initial_paragraph: str,
    source_story_paragraphs: List[str],
    transitions: List[str],
    phonemes: List[str],
    target_paragraph_count: int = 7,
) -> List[str]:
    story = [initial_paragraph]

    # Puts together the list of six transitions and seven paragraphs.
    while len(transitions) < target_paragraph_count - 1:
        # If not enough transitions just uses a continuation transition.
        transitions.append("Continue the story.")
    while len(source_story_paragraphs) < target_paragraph_count:
        source_story_paragraphs.append("")

    # Generates six paragraphs, and puts them together into a single text separated into paragraphs and with the
    # theme of the story and transition into the paragraph above each paragraph. The phonemes incorporated are given with the initial
    # paragraph only.
    for i in range(1, target_paragraph_count):
        transition = transitions[i - 1]
        prev_source = source_story_paragraphs[i - 1] if i - 1 >= 0 else ""
        current_source = source_story_paragraphs[i]

        new_paragraph = generate_continuation_paragraph(
            theme=theme,
            phonemes = load_mistakes(MISTAKES_FILE),
            story_so_far=story,
            previous_source_paragraph=prev_source,
            current_source_paragraph=current_source,
            transition_text=transition,
            llama_cli_path=LLAMA_CLI_PATH,
            model_path=MODEL_PATH,
            max_context_tokens=MAX_CONTEXT_TOKENS,
            max_generation_tokens_per_batch=MAX_GENERATION_TOKENS_PER_BATCH
        )

        formatted = f"---Theme: {theme}---\n--- Transition: {transition}---{new_paragraph.strip()}"
        story.append(formatted)

    return story, phonemes

# Main method for calling all the other methods.
if __name__ == "__main__":
    source_file = SOURCE_FILE
    output_file = OUTPUT_FILE

    with open(source_file, "r", encoding="utf-8") as f:
        all_text = f.read()

    # Splits the file of matched stories into individual stories.
    blocks = re.split(r"(?=--- Matched Story \d+ .*?---)", all_text)

    idx = 0
    # Processes each individual matched story.
    for block in blocks:
        if not block.strip():
            continue
        idx = idx + 1

        story_id_match = re.search(r"--- Matched Story (\d+) .*?---", block)

        if not story_id_match:
            continue

        story_id = int(story_id_match.group(1))

        try:
            paragraphs, transitions = extract_story_paragraphs_and_transitions(
                filepath=None,
                story_number=story_id
            )
        except Exception:
            def extract_story_paragraphs_and_transitions_from_text(text: str):
                paragraphs = re.findall(r"\[Paragraph \d+\](.*?)\n(?=\[|\Z)", text, re.DOTALL)
                paragraphs = [p.strip() for p in paragraphs if p.strip()]

                transitions = []
                if "--- Paragraph Transitions ---" in text:
                    trans_block = text.split("--- Paragraph Transitions ---", 1)[-1]
                    raw_trans = re.findall(r"\[Transition \d+\]\s*(.*?)(?=\n\[Transition|\Z)", trans_block, re.DOTALL)
                    transitions = [t.strip() for t in raw_trans if t.strip()]

                return paragraphs, transitions

            paragraphs, transitions = extract_story_paragraphs_and_transitions_from_text(block)

        if not paragraphs:
            print(f"‚ùå No paragraphs found for Matched Story {story_id}, skipping.")
            continue

        themes = load_themes(THEME_FILE)
        if not themes:
            print("No themes loaded.")
            exit()
        random_int = random.randint(0, len(themes)-1)
        theme, theme_sentence = themes[random_int]

        # First paragraph is used as initial source paragraph.
        initial_paragraph = paragraphs[0]

        full_story, phonemes = build_story(theme, initial_paragraph, paragraphs, transitions, phonemes = load_mistakes("phonemes.txt"), target_paragraph_count=7)
        output_file = "generated_story_output_no_outline.txt"
        
        # Saves the generateed story.
        with open(output_file, "a", encoding="utf-8") as f_out:
            f_out.write(f"--- Generated Story {idx} (From Matched Story {story_id}) ---\n\n")
            f_out.write(f"--- Phonemes Incorporated: {phonemes[0]}, {phonemes[1]}, {phonemes[2]}, {phonemes[3]}, {phonemes[4]} ---\n")
            f_out.write(f"--- Theme: {theme} ---\n")
            for para in full_story:
                clean_para = para.replace("[end of text]", "").replace("assistant", "").strip()
                f_out.write(clean_para + "\n\n")

